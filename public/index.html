<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Porcupine Wakeword Test (Browser)</title>
  <style>
    body{font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial;max-width:760px;margin:3rem auto;padding:1rem}
    button{padding:.6rem 1rem;margin:.4rem}
    .badge{display:inline-block;padding:.3rem .6rem;border-radius:.5rem;background:#eee}
    #log{white-space:pre-wrap;background:#111;color:#0f0;padding:1rem;border-radius:.5rem;height:220px;overflow:auto}
  </style>
</head>
<body>
  <h1>Porcupine Wakeword â€” Browser Recorder</h1>
  <p>This page records your microphone, resamples to 16 kHz PCM16LE in the browser, and streams frames to the server's <code>/audio?sessionId=...</code> endpoint.</p>

  <div>
    <button id="startBtn">Start</button>
    <button id="stopBtn" disabled>Stop</button>
    <button id="testBtn">Test Server (Start Session)</button>
    <span class="badge" id="state">idle</span>
  </div>

  <h3>Server info</h3>
  <div>Session id: <span id="sessionId">-</span></div>
  <div>Server sampleRate/frameLength: <span id="spec">-</span></div>

  <h3>Log</h3>
  <div id="log">open console or press Test Server to start a session</div>

<script>
(async function(){
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const testBtn = document.getElementById('testBtn');
  const stateBadge = document.getElementById('state');
  const sessionSpan = document.getElementById('sessionId');
  const specSpan = document.getElementById('spec');
  const logEl = document.getElementById('log');

  function log(...s){ logEl.textContent = new Date().toISOString() + '  ' + s.join(' ') + '
' + logEl.textContent }

  let mediaStream=null, audioCtx=null, processor=null, source=null;
  let session=null; // {sessionId, sampleRate, frameLength}
  let sendUrlBase = (location.origin);

  async function startSession(){
    const r = await fetch('/session/start', { method: 'POST' });
    session = await r.json();
    sessionSpan.textContent = session.sessionId;
    specSpan.textContent = session.sampleRate + ' / ' + session.frameLength;
    log('session started', JSON.stringify(session));
    return session;
  }

  async function startRecording(){
    if (!session) await startSession();
    // get microphone
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    await audioCtx.audioWorklet || null; // no-op but helps some browsers

    source = audioCtx.createMediaStreamSource(mediaStream);

    // Use ScriptProcessor as it's simpler and widely supported (bufferSize 4096). We will read Float32 samples.
    const bufferSize = 4096;
    processor = audioCtx.createScriptProcessor(bufferSize, 1, 1);

    // resampling helper: downsample Float32Array from audioCtx.sampleRate to 16000
    function downsampleBuffer(buffer, inputSampleRate, outputSampleRate){
      if (outputSampleRate === inputSampleRate) return buffer;
      const sampleRateRatio = inputSampleRate / outputSampleRate;
      const newLength = Math.round(buffer.length / sampleRateRatio);
      const result = new Float32Array(newLength);
      let offsetResult = 0;
      let offsetBuffer = 0;
      while (offsetResult < result.length){
        const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
        // average the samples between offsetBuffer and nextOffsetBuffer
        let accum = 0, count = 0;
        for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++){
          accum += buffer[i]; count++;
        }
        result[offsetResult] = count ? (accum / count) : 0;
        offsetResult++;
        offsetBuffer = nextOffsetBuffer;
      }
      return result;
    }

    // convert Float32 [-1..1] -> Int16 LE
    function int16FromFloat32(float32Array){
      const l = float32Array.length;
      const buf = new ArrayBuffer(l * 2);
      const view = new DataView(buf);
      for (let i = 0; i < l; i++){
        let s = Math.max(-1, Math.min(1, float32Array[i]));
        view.setInt16(i*2, s < 0 ? s*0x8000 : s*0x7FFF, true);
      }
      return new Int16Array(buf);
    }

    // We'll buffer PCM data until we have at least frameLength samples, then send them.
    let pcmBuffer = new Int16Array(0);
    const targetSampleRate = 16000;
    const frameLength = session.frameLength; // samples per frame
    const frameByteLen = frameLength * 2;

    processor.onaudioprocess = async (evt) => {
      const inputData = evt.inputBuffer.getChannelData(0); // Float32Array
      const down = downsampleBuffer(inputData, audioCtx.sampleRate, targetSampleRate);
      const int16 = int16FromFloat32(down);

      // append to pcmBuffer
      const tmp = new Int16Array(pcmBuffer.length + int16.length);
      tmp.set(pcmBuffer, 0);
      tmp.set(int16, pcmBuffer.length);
      pcmBuffer = tmp;

      // send out all full frames (frameLength samples)
      while (pcmBuffer.length * 2 >= frameByteLen){
        const sendSamples = pcmBuffer.subarray(0, frameLength);
        // create a little-endian ArrayBuffer
        const ab = new ArrayBuffer(sendSamples.length * 2);
        const dv = new DataView(ab);
        for (let i = 0; i < sendSamples.length; i++) dv.setInt16(i*2, sendSamples[i], true);

        // POST to server
        navigator.sendBeacon = navigator.sendBeacon || undefined; // keep lint quiet
        fetch('/audio?sessionId=' + session.sessionId, { method: 'POST', headers: { 'Content-Type': 'application/octet-stream' }, body: ab })
          .then(r=>r.json()).then(j=>{ if (j.detected) { stateBadge.textContent = 'wakeword detected'; log('detected', JSON.stringify(j)); } })
          .catch(e=> log('POST error', e));

        // slice the buffer
        pcmBuffer = pcmBuffer.subarray(frameLength);
      }
    };

    source.connect(processor);
    processor.connect(audioCtx.destination);

    startBtn.disabled = true; stopBtn.disabled = false; stateBadge.textContent = 'recording'; log('recording started');
  }

  function stopRecording(){
    if (processor) { processor.disconnect(); processor.onaudioprocess = null; processor = null; }
    if (source) { source.disconnect(); source = null; }
    if (audioCtx) { try{ audioCtx.close(); }catch(e){} audioCtx = null; }
    if (mediaStream) { mediaStream.getTracks().forEach(t=>t.stop()); mediaStream = null; }
    startBtn.disabled = false; stopBtn.disabled = true; stateBadge.textContent = 'idle'; log('stopped');
  }

  startBtn.addEventListener('click', async ()=>{
    try{ await startRecording(); }catch(e){ log('start error', e); }
  });
  stopBtn.addEventListener('click', ()=> stopRecording());

  testBtn.addEventListener('click', async ()=>{
    try{
      await startSession();
    }catch(e){ log('session start failure', e); }
  });

})();
</script>
</body>
</html>
